# Decision Trees
Slides: https://eo4geocourses.github.io/UT-ITC_Satellite_Data_Classification_Decision_Trees

Created by: Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente

Abstract:
Decision Trees (DT) is a non-parametric classifier that gained popularity in different domains because its structure is explicit and easily interpretable. A DT is built by recursively splitting each tree node using a statistical procedure such as Gini impurity measure, information gain (for classification scenarios), or variance (for prediction problems). In this lecture, we will be introducing the main steps required for building a DT. Two procedures used to select the best variables for splitting the tree nodes will be discussed by making use of a practical example. These procedures include Gini impurity and information gain. The overfitting and underfitting concepts will be explained in the second part of the lecture when we will introduce two solutions to build the optimal DT, i.e. a DT that does not overfit: (1) stop growing the DT early before overfitting and (2)pruning or reducing the size of the tree. The lecture ends up by listing the main advantages and disadvantages of DT.

Table of contents:
(1) General Information; 
(2) Decision Trees components; 
(3) Criteria for nodes splitting; 
(4) Overfitting and underfitting concepts; 
(5)  Decision Trees pruning; 
(6) Decision Trees algorithms

Learning outcomes
LO1: Explain how information gain and Gini impurity is calculated
LO2: Present the main advantages and disadvantages of decision trees classifier
LO2: Describe the concept of over-fitting and under-fitting
LO4: Define the main solutions that can be applied to avoid decision trees over-fitting


